{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwtFpdfHMZcujuMq/ia1iC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rianbl/datarvw_spark/blob/main/datareview_spark_config.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1K_GhwMAZaYPEqm-0ukMBxfmBew7N6GXA)<br>\n",
        "<small>Rian Lopes</small><br>\n",
        "\n",
        "Inscreva-se no canal <br>[Data Review](https://www.youtube.com/channel/UCYfY8KRS5nqoFBTuoLV0_jw) <br>\n",
        "E siga nas redes sociais <br> [Instagram Data Review](https://www.instagram.com/data.review/)\n",
        "<br>\n",
        "<br>\n",
        "<h1>Spark for Data Science and Machine Learning</h1>\n",
        "<h2>Environment config</h2>\n"
      ],
      "metadata": {
        "id": "5lfKXKxtte_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação das dependências\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!pip install -q pyspark"
      ],
      "metadata": {
        "id": "4e3exIRMgLh-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Baixar e instalar o Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "AuLS1bdogOWt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração das variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "FFUZ36sOgQ6d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar e chamar o Findspark para reconhecer o caminho dos binários do Spark\n",
        "!pip install findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "memgfVPqgTUd",
        "outputId": "d9186aeb-6825-426b-9fc7-91b41a513430"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicialização do Spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"HellorWorld\") \\\n",
        "    .getOrCreate()\n",
        "\n"
      ],
      "metadata": {
        "id": "nZ6OrwOMaJa6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "3ITy8W4jolCq",
        "outputId": "c6c8005e-9514-4eb4-ae05-06d96733f051"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a2fe830d010>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://feb400a412fc:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>ColabDemo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Criação de um DataFrame simples\n",
        "data = [(\"Olá, Mundo\",)]\n",
        "colunas = [\"Mensagem\"]\n",
        "df = spark.createDataFrame(data, colunas)\n",
        "\n",
        "# Exibição do DataFrame\n",
        "print(\"DataFrame exemplo:\")\n",
        "df.show()\n",
        "\n",
        "# Exibir schema\n",
        "print(\"Schema do DataFrame:\")\n",
        "df.printSchema()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqz_vsklgmme",
        "outputId": "c8e04db8-7bc9-4a73-d52f-fcf28617b6c6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame exemplo:\n",
            "+----------+\n",
            "|  Mensagem|\n",
            "+----------+\n",
            "|Olá, Mundo|\n",
            "+----------+\n",
            "\n",
            "Schema do DataFrame:\n",
            "root\n",
            " |-- Mensagem: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encerrar sessão Spark\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "6j7R4FM8u1CO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "subprocess.run(['java', '-version'], capture_output=True, text=True).stderr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "k4P7o14Bwmcl",
        "outputId": "7cdaceec-77f6-4329-f5f9-db802398c8cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'openjdk version \"11.0.26\" 2025-01-21\\nOpenJDK Runtime Environment (build 11.0.26+4-post-Ubuntu-1ubuntu122.04)\\nOpenJDK 64-Bit Server VM (build 11.0.26+4-post-Ubuntu-1ubuntu122.04, mixed mode, sharing)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "subprocess.run(['spark-submit', '--version'], capture_output=True, text=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJJf5w1Fdzz3",
        "outputId": "c331330c-e8bb-46e5-ce63-da8fe32aec54"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['spark-submit', '--version'], returncode=0, stdout='', stderr=\"Welcome to\\n      ____              __\\n     / __/__  ___ _____/ /__\\n    _\\\\ \\\\/ _ \\\\/ _ `/ __/  '_/\\n   /___/ .__/\\\\_,_/_/ /_/\\\\_\\\\   version 3.5.0\\n      /_/\\n                        \\nUsing Scala version 2.12.18, OpenJDK 64-Bit Server VM, 11.0.26\\nBranch HEAD\\nCompiled by user ubuntu on 2023-09-09T01:53:20Z\\nRevision ce5ddad990373636e94071e7cef2f31021add07b\\nUrl https://github.com/apache/spark\\nType --help for more information.\\n\")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}